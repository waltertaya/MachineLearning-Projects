{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pp3SSHgCLSWI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xBXt5vHGLSWJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/home/waltertaya/ML/Batch-Gradient-Descent/housing.csv', header=None)\n",
        "df.columns = ['Number of bedrooms', 'Sizes of the house(feet sqrd)', 'Prices in dollars']\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L0IfC2wqLSWK"
      },
      "outputs": [],
      "source": [
        "X = np.array(df.drop('Prices in dollars', axis=1))\n",
        "y = np.array(df['Prices in dollars'])\n",
        "# print(X)\n",
        "# print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GpIudZrkLSWK"
      },
      "outputs": [],
      "source": [
        "def predict(X,w,b):\n",
        "    y_pred = []\n",
        "    return np.array(np.matmul(w, X.T) + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CBBAonuXLSWK"
      },
      "outputs": [],
      "source": [
        "def cost_func(y, y_pred):\n",
        "    n = len(y)\n",
        "    cost = 0\n",
        "    for i in range(1, n):\n",
        "        cost += (y[i] - y_pred[i])**2\n",
        "    return cost / n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3f6Wx35eLSWK"
      },
      "outputs": [],
      "source": [
        "def batch_gradient_descent(X, y, w, b, learning_rate, iterations):\n",
        "    N = len(y)  # Number of data points\n",
        "    for i in range(iterations):\n",
        "        # Predictions\n",
        "        y_pred = predict(X, w, b)\n",
        "\n",
        "        # Compute gradients\n",
        "        dw = -(2/N) * np.dot(X.T, (y - y_pred))  # Gradient w.r.t weights\n",
        "        db = -(2/N) * np.sum(y - y_pred)         # Gradient w.r.t bias\n",
        "\n",
        "        # Update weights and bias\n",
        "        w -= learning_rate * dw\n",
        "        b -= learning_rate * db\n",
        "\n",
        "        # Optionally, print the cost every 100 iterations for monitoring\n",
        "        if i % 100 == 0:\n",
        "            cost = cost_func(y, y_pred)\n",
        "            print(f\"Iteration {i}: Cost = {cost}\")\n",
        "\n",
        "    return w, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wsKoiqmLSWK",
        "outputId": "a6f4d1eb-17d4-4e47-a522-6c0dd1c73417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0: Cost = 248886.36363636365\n",
            "Iteration 100: Cost = 5595.894553587888\n",
            "Iteration 200: Cost = 1464.1754085851371\n",
            "Iteration 300: Cost = 946.4241206861439\n",
            "Iteration 400: Cost = 655.3719839250393\n",
            "Iteration 500: Cost = 459.3341293030831\n",
            "Iteration 600: Cost = 325.118610994839\n",
            "Iteration 700: Cost = 233.0537321983769\n",
            "Iteration 800: Cost = 169.90980703403727\n",
            "Iteration 900: Cost = 126.62481325294056\n",
            "Trained weights: [ 14.05305762 231.89793199]\n",
            "Trained bias: 440.4545447132748\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize the features using StandardScaler (or MinMaxScaler)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "# Run gradient descent\n",
        "w, b = batch_gradient_descent(X_scaled, y, w, b, learning_rate, iterations)\n",
        "\n",
        "# Final weights and bias after training\n",
        "print(f\"Trained weights: {w}\")\n",
        "print(f\"Trained bias: {b}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6BnyU_hMbQ-",
        "outputId": "35dfed79-5081-4f4e-d03d-2bfd337b917a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[264.50741284 265.35441967 362.26796078 441.65195812 171.11003105\n",
            " 735.83186157 264.48178644 507.12507663 771.55857111 899.86128202\n",
            " 156.24963977]\n",
            "96.31045408478899\n"
          ]
        }
      ],
      "source": [
        "w = np.array([ 14, 233])\n",
        "b = 440\n",
        "y_pred = predict(X_scaled, w, b)\n",
        "print(y_pred)\n",
        "print(cost_func(y, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
